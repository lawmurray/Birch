/*
 * Take the exponential of a value, where NaN is treated as though `-inf`.
 */
function nan_exp(x:Real) -> Real {
  if isnan(x) {
    return 0.0;
  } else {
    return exp(x);
  }
}

/*
 * Take the maximum of two values, where NaN are treated as though `-inf`.
 */
function nan_max(x:Real, y:Real) -> Real {
  if isnan(x) && isnan(y) {
    return -inf;
  } else if isnan(x) {
    return y;
  } else if isnan(y) {
    return x;
  } else {
    return max(x, y);
  }
}

/*
 * Find the maximum of a log weight vector, where NaN are treated as though
 * `-inf`.
 */
function nan_max(w:Real[_]) -> Real {
  return reduce(w, -inf, \(x:Real, y:Real) -> { return nan_max(x, y); });
}

/*
 * Exponentiate and sum a log weight vector.
 *
 * @param w Log weights.
 *
 * @return the logarithm of the sum.
 *
 * @note
 *     NaN log weights are treated as though `-inf`.
 *
 * This uses a numerically stable implementation that avoids over- and
 * underflow, using a single pass over the data.
 * It is based on:
 *
 * S. Nowozin (2016). Streaming Log-sum-exp Computation.
 * http://www.nowozin.net/sebastian/blog/streaming-log-sum-exp-computation.html
 */
function log_sum_exp(w:Real[_]) -> Real {
  if length(w) > 0 {
    let mx <- -inf; // running maximum of log weights
    /*
     * Running sum of non-maximum weights divided by maximum weight.
     * In contrast to Nowozin's implementation the maximum itself
     * is not included in the sum.
     * This avoids underflow for e.g. w = [1e-20, log(1e-20)].
     */
    let r <- 0.0;
    for n in 1..length(w) {
      let wn <- w[n];
      if wn == inf {
        return inf;
      } else if wn > mx {
        r <- (r + 1.0)*exp(mx - wn);
        mx <- wn;
      } else if isfinite(wn) {
        r <- r + exp(wn - mx);
      }
    }
    return mx + log1p(r);
  } else {
    return -inf;
  }
}

/*
 * Convert a log weight vector into a normalized weight vector.
 *
 * @param w Log weights.
 *
 * @return normalized weights.
 *
 * !!! note
 *     NaN log weights are treated as though `-inf`.
 */
function norm_exp(w:Real[_]) -> Real[_] {
  if length(w) == 0 {
    return w;
  } else {
    let W <- log_sum_exp(w);
    return transform(w, \(x:Real) -> { return nan_exp(x - W); });
  }
}

/*
 * Resample with systematic resampling.
 *
 * @param w Log weights.
 *
 * @return the vector of ancestor indices (permuted) and vector of offspring
 * counts.
 *
 * See also: permute_ancestors()
 *
 * !!! note
 *     NaN log weights are treated as though `-inf`.
 */
function resample_systematic(w:Real[_]) -> (Integer[_], Integer[_]) {
  let O <- systematic_cumulative_offspring(cumulative_weights(w));
  let a <- permute_ancestors(cumulative_offspring_to_ancestors(O));
  let o <- cumulative_offspring_to_offspring(O);
  return (a, o);
}

/*
 * Resample with multinomial resampling.
 *
 * @param w Log weights.
 *
 * @return the vector of ancestor indices, in non-descending order.
 *
 * !!! note
 *     NaN log weights are treated as though `-inf`.
 */
function resample_multinomial(w:Real[_]) -> Integer[_] {
  return offspring_to_ancestors(simulate_multinomial(length(w),
      norm_exp(w)));
}

/*
 * Sample a single ancestor for a cumulative weight vector.
 *
 * @param W Cumulative weight vector.
 *
 * @return an ancestor index, or zero on failure (e.g. weights are zero).
 *
 * !!! note
 *     NaN log weights are treated as though `-inf`.
 */
function cumulative_ancestor(W:Real[_]) -> Integer {
  let n <- 0;
  let N <- length(W);
  if N > 0 && W[N] > 0.0 {
    /* binary search for uniform random variate */
    let u <- simulate_uniform(0.0, W[N]);
    let l <- 0;
    let r <- N;
    while l < r {
      n <- (l + r)/2;
      if W[n + 1] < u {
        l <- n + 1;
      } else {
        r <- n;
      }
    }
    n <- l + 1;
  }
  assert n <= N;
  return n;
}

/*
 * Sample a single ancestor for a log weight vector.
 *
 * @param w Log weight vector.
 *
 * @return an ancestor index, or zero on failure (e.g. weights are zero).
 *
 * !!! note
 *     NaN log weights are treated as though `-inf`.
 */
function ancestor(w:Real[_]) -> Integer {
  return cumulative_ancestor(cumulative_weights(w));
}

/*
 * Systematic resampling.
 */
function systematic_cumulative_offspring(W:Real[_]) -> Integer[_] {
  let N <- length(W);
  O:Integer[N];
  let u <- simulate_uniform(0.0, 1.0);
  for n in 1..N {
    let r <- N*W[n]/W[N];
    O[n] <- min(N, cast<Integer>(r + u));
  }
  return O;
}

/*
 * Convert an offspring vector into an ancestry vector.
 */
function offspring_to_ancestors(o:Integer[_], N:Integer) -> Integer[_] {
  a:Integer[N];
  let i <- 1;
  for n in 1..length(o) {
    for j in 1..o[n] {
      a[i] <- n;
      i <- i + 1;
      assert i <= N + 1;
    }
  }
  assert i == N + 1;
  assert is_sorted(a);
  return a;
}

/*
 * Convert an offspring vector into an ancestry vector.
 */
function offspring_to_ancestors(o:Integer[_]) -> Integer[_] {
  return offspring_to_ancestors(o, length(o));
}

/*
 * Convert a cumulative offspring vector into an ancestry vector.
 */
function cumulative_offspring_to_ancestors(O:Integer[_]) -> Integer[_] {
  let N <- length(O);
  a:Integer[N];
  for n in 1..N {
    let start <- 0;
    if n > 1 {
      start <- O[n - 1];
    }
    let o <- O[n] - start;
    for j in 1..o {
      a[start + j] <- n;
    }
  }
  assert is_sorted(a);
  return a;
}

/*
 * Convert a cumulative offspring vector into an offspring vector.
 */
function cumulative_offspring_to_offspring(O:Integer[_]) -> Integer[_] {
  return adjacent_difference(O, \(x:Integer, y:Integer) -> Integer {
        return x - y;
      });
}

/*
 * Permute an ancestry vector to ensure that, when a particle survives, at
 * least one of its instances remains in the same place.
 */
function permute_ancestors(a:Integer[_]) -> Integer[_] {
  let N <- length(a);
  let b <- a;
  let n <- 1;
  while n <= N {
    let c <- b[n];
    if c != n && b[c] != c {
      b[n] <- b[c];
      b[c] <- c;
    } else {
      n <- n + 1;
    }
  }
  return b;
}

/*
 * Compute the cumulative weight vector from the log-weight vector.
 */
function cumulative_weights(w:Real[_]) -> Real[_] {
  let N <- length(w);
  W:Real[N];
  if N > 0 {
    let mx <- nan_max(w);
    W[1] <- nan_exp(w[1] - mx);
    for n in 2..N {
      W[n] <- W[n - 1] + nan_exp(w[n] - mx);
    }
  }
  return W;
}

/*
 * Compute the effective sample size (ESS) and logarithm of the average
 * weight, given a log-weight vector.
 *
 * @return A pair, the first element of which gives the ESS, the second
 * element of which gives the logarithm of the sum of weights.
 *
 * @note
 *     NaN log weights are treated as though `-inf`.
 *
 * This uses a numerically stable implementation that avoids over- and
 * underflow, using a single pass over the data.
 * It is based on:
 *
 * S. Nowozin (2016). Streaming Log-sum-exp Computation.
 * http://www.nowozin.net/sebastian/blog/streaming-log-sum-exp-computation.html
 */
function resample_reduce(w:Real[_]) -> (Real, Real) {
  if length(w) == 0 {
    return (0.0, -inf);
  } else {
    let mx <- -inf; // running maximum of log weights
    /*
     * Running sum of non-maximum weights divided by maximum weight (r),
     * and their squares (q).
     * In contrast to Nowozin's implementation the maximum itself
     * is not included in the sum.
     * This avoids underflow for e.g. w = [1e-20, log(1e-20)].
     */
    let r <- 0.0;
    let q <- 0.0;
    for n in 1..length(w) {
      let wn <- w[n];
      if wn == inf {
        return (1.0, inf);
      } else if wn > mx {
        let v <- exp(mx - wn);
        r <- (r + 1.0)*v;
        q <- (q + 1.0)*v*v;
        mx <- wn;
      } else if isfinite(wn) {
        let v <- exp(wn - mx);
        r <- r + v;
        q <- q + v*v;
      }
    }

    /* if all weights are `-inf` or `nan`, the result is the same as for empty arrays */
    if mx==-inf {
      return (0.0, -inf);
    }

    let log_sum_weights <- mx + log1p(r);
    /* the ESS is estimated as (sum w)^2 / (sum w^2) */
    let rp1 <- r + 1.0;
    let ess <- rp1*rp1/(q + 1.0);
    return (ess, log_sum_weights);
  }
}
